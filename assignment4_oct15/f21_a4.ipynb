{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 (Oct 12)\n",
    "\n",
    "Today we will talk about **Monte Carlo (MC)** methods, techniques that involve random sampling. But before we dive into that, \n",
    "we will need to learn a little bit about random numbers in Python.\n",
    "\n",
    "We will go over:\n",
    "\n",
    "1. Python Numpy Random Generator: `np.random.default_rng()`\n",
    "2. Plot histogram\n",
    "3. Monte Carlo -- Uncertainty Propagation\n",
    "4. Monte Carlo -- Bootstrapping\n",
    "\n",
    "## Readings (optional)\n",
    "\n",
    "If you find this week's material new or challenging, you may want to read through some or all the following resources while working on your assignment:\n",
    "\n",
    "- [SPIRL Ch. 3.6. Conditionals](https://cjtu.github.io/spirl/python_conditionals.html#conditionals)\n",
    "- [Numpy Random Generator](https://numpy.org/doc/stable/reference/random/generator.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Number Generators (RNGs)\n",
    "\n",
    "To work with random numbers in Python, we can use the `random` module within `numpy`.\n",
    "\n",
    "### Pseudo-random number generators (PRNG)\n",
    "\n",
    "It might sound easy to come up with a random number, but many surveys have found this to not be the case (e.g. [Asking 8500 students to pick a random number](https://www.reddit.com/r/dataisbeautiful/comments/acow6y/asking_over_8500_students_to_pick_a_random_number/)).\n",
    "\n",
    "Because computers are deterministic (a collection of switches that can be \"on\" or \"off\"), it is surprisingly hard to produce a set of numbers that are truly random.  Luckily, we often don't need a *truly* random set of numbers. Usually when we say we want random numbers, we want a set of numbers that are:\n",
    "\n",
    "- not biased to any particular value \n",
    "- contain no repeated or recognizable patterns\n",
    "\n",
    "This is where a **pseudorandom number generator (PRNG)** can help.\n",
    "\n",
    "See what Wikipedia tell us about the PRNG:\n",
    "\n",
    "> A pseudorandom number generator (PRNG), also known as a deterministic random bit generator (DRBG), is an algorithm for generating a sequence of numbers whose properties approximate the properties of sequences of random numbers. The PRNG-generated sequence is not truly random, because it is completely determined by an initial value, called the PRNG's seed (which may include truly random values).\n",
    "\n",
    "The key \"flaw\" with a PRNG is that if you know a special value called the **seed**, you can regenerate the exact same sequence of random numbers again. But this ends up being a useful *feature* of PRNGs as we'll see later.\n",
    "\n",
    "Since all computer generated random number generators are PRNGs, we often just drop the \"P\" and simply call them **random number generators (RNGs)** (but now you know their secret).\n",
    "\n",
    "Read more about [Pseudorandom number generators on Wikipedia](https://en.wikipedia.org/wiki/Pseudorandom_number_generator).\n",
    "\n",
    "### NumPy Random Module (`np.random`)\n",
    "\n",
    "In NumPy, there are two ways to generate random numbers:\n",
    "\n",
    "- Calling functions in `random` directly (**deprecated**): `np.random.func()`\n",
    "- Generating an `rng` object with `obj = np.random.default_rng()` and calling methods on it: `obj.method()`\n",
    "\n",
    "There are also different algorithms you can use to generate random numbers and if you mix and match RNG algorithms, you won't be guaranteed the same random numbers even if you know the **seed**. This is why random numbers in different programming languages won't necessarily be the same with the same seed (read more about [NumPy bit generators](https://numpy.org/doc/stable/reference/random/bit_generators/index.html)). For almost all applications, the `default_random` from NumPy is sufficient (see [NumPy simple random data](https://numpy.org/doc/stable/reference/random/generator.html#simple-random-data). Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the random number generator object\n",
    "rng = np.random.default_rng()\n",
    "# help(rng.integers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first try to genertae random intergers with\n",
    "\n",
    "```\n",
    "integers(low, high=None, size=None, dtype=np.int64, endpoint=False)\n",
    "\n",
    "Return random integers from `low` (inclusive) to `high` (exclusive), or\n",
    "if endpoint=True, `low` (inclusive) to `high` (inclusive). Replaces\n",
    "`RandomState.randint` (with endpoint=False) and\n",
    "`RandomState.random_integers` (with endpoint=True)\n",
    "\n",
    "Return random integers from the \"discrete uniform\" distribution of\n",
    "the specified dtype. If `high` is None (the default), then results are\n",
    "from 0 to `low`.\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw random intergers from the range `draw_range` `ndraws` times.\n",
    "draw_range = (0, 10)  # (low, high)\n",
    "ndraws = 8  # how many to generate or \"draw\"\n",
    "\n",
    "random_ints = rng.integers(*draw_range, ndraws)\n",
    "\n",
    "print(random_ints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use `for` loop to run it many times to see if any are duplicated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "for i in range(10):\n",
    "    random_ints = rng.integers(*draw_range, ndraws)\n",
    "    print(f'Run {i}: ', random_ints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But remember: these are *pseudo*random numbers, meaning we can generate the same random sequence again if we know the **seed** value.\n",
    "\n",
    "This time, see what happens when we re-make the rng object with the same seed each time in the loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_range = (0, 10)\n",
    "ndraws = 10\n",
    "seed = 100\n",
    " \n",
    "for i in range(10):\n",
    "    rng = np.random.default_rng(seed=seed)  # seed the default RNG\n",
    "    random_ints = rng.integers(*draw_range, ndraws)\n",
    "    print(f'run {i} give: ', random_ints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot histogram with `plt.hist`\n",
    "\n",
    "We can verify how random our values are using a histogram.\n",
    "\n",
    "`help(plt.hist)`\n",
    "\n",
    "```\n",
    "hist(x, bins=None, range=None, density=None, weights=None, cumulative=False, bottom=None, histtype='bar', align='mid', orientation='vertical', rwidth=None, log=False, color=None, label=None, stacked=False, normed=None, *, data=None, **kwargs)\n",
    "    Plot a histogram.\n",
    "...\n",
    "    Returns\n",
    "    -------\n",
    "    n : array or list of arrays\n",
    "        The values of the histogram bins. See *density* and *weights* for a\n",
    "        description of the possible semantics.  If input *x* is an array,\n",
    "        then this is an array of length *nbins*. If input is a sequence of\n",
    "        arrays ``[data1, data2,..]``, then this is a list of arrays with\n",
    "        the values of the histograms for each of the arrays in the same\n",
    "        order.  The dtype of the array *n* (or of its element arrays) will\n",
    "        always be float even if no weighting or normalization is used.\n",
    "    \n",
    "    bins : array\n",
    "        The edges of the bins. Length nbins + 1 (nbins left edges and right\n",
    "        edge of last bin).  Always a single array even when multiple data\n",
    "        sets are passed in.\n",
    "    \n",
    "    patches : list or list of lists\n",
    "        Silent list of individual patches used to create the histogram\n",
    "        or list of such list if multiple input datasets.\n",
    "...\n",
    "```\n",
    "\n",
    "We will also use a convenient helper function to take care of some of our plot formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to apply the same format to each plot, we can make it a function!\n",
    "def set_plot_axis_label(ax, xlabel, ylabel):\n",
    "    \"\"\"\n",
    "    Set formatting options on a matplotlib ax object.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ax : matplotlib.axes.Axes\n",
    "        The ax object to format.\n",
    "    xlabel : str\n",
    "        The x-axis label.\n",
    "    ylabel : str\n",
    "        The y-axis label.\n",
    "    \"\"\"\n",
    "    ax.tick_params(axis='both', which ='both', labelsize='small', right=True, \n",
    "                     top=True, direction='in')   \n",
    "    ax.set_xlabel(xlabel, size='medium', fontname='Helvetica')\n",
    "    ax.set_ylabel(ylabel, size='medium', fontname='Helvetica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random number setup\n",
    "draw_range = (0, 10)\n",
    "ndraws = 10000  # Try doing different numbers of draws\n",
    "\n",
    "# Do random draws\n",
    "rng = np.random.default_rng()  \n",
    "random_ints = rng.integers(*draw_range, ndraws)\n",
    "\n",
    "# Set up plot and plot the histogram\n",
    "fig, axs = plt.subplots(1, 2, facecolor='white', figsize=(8, 3), dpi=150)\n",
    "\n",
    "# Default hist\n",
    "n, edges, _ = axs[0].hist(random_ints)\n",
    "set_plot_axis_label(axs[0], 'Value', 'Count')  # Our helper function\n",
    "\n",
    "\n",
    "# Center the bins and show as a \"step\" function\n",
    "n, edges, _ = axs[1].hist(random_ints, range=(-0.5, 9.5), bins=10, \n",
    "                          histtype='step')\n",
    "set_plot_axis_label(axs[1], 'Value', 'Count')  # Our helper function\n",
    "\n",
    "# add subticks for both axises\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "for axi in range(2):\n",
    "    axs[axi].xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "    axs[axi].yaxis.set_minor_locator(AutoMinorLocator(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what our histogram actually gave us in the `n` and `edges` it returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number in each bins: {n}')\n",
    "print(f'Edges of each bin: {edges}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's overplot these data points back to the histogram.\n",
    "\n",
    "But, before that, we need to find out the center values of the each bins (we only have the left and right edges currently).\n",
    "\n",
    "### [Short Quiz] Find the bin centers from `edges` array \n",
    "\n",
    "Try to write code to covert bin edges to bin centers (copying the following list is cheating! We want to do it in general).\n",
    "\n",
    "```python\n",
    "edges = [-0.5  0.5  1.5  2.5  3.5  4.5  5.5  6.5  7.5  8.5  9.5]\n",
    "```\n",
    "into\n",
    "```python\n",
    "bin_center = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put you code here, you have 5 mins\n",
    "edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whichever way you figured out how to compute the bin centers, we can now plot them on our histogram!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random number setup\n",
    "draw_range = (0, 10)\n",
    "ndraws = 1000\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "random_ints = rng.integers(*draw_range, \n",
    "                            ndraws)\n",
    "\n",
    "# plotting\n",
    "f = plt.figure(facecolor='white', figsize=(4,3), dpi=150 )\n",
    "ax1 = f.subplots(1, 1)\n",
    "\n",
    "# plot the histogram\n",
    "n, edges, _ = ax1.hist(random_ints, range = (-0.5, 9.5), bins=10, histtype='step')\n",
    "\n",
    "bin_center = (edges[:-1] + edges[1:])/2\n",
    "ax1.plot(bin_center, n, '.', ms=3, c='tab:red')\n",
    "set_plot_axis_label(ax1, 'Value', 'Count')\n",
    "\n",
    "\n",
    "ax1.xaxis.set_minor_locator(AutoMinorLocator(2))\n",
    "ax1.yaxis.set_minor_locator(AutoMinorLocator(5))\n",
    "ax1.grid(lw=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy Random - random draws from a distribution\n",
    "\n",
    "We can draw from a variety of statistical distributions using our `numpy.random.default_rng` object (see all of them at [NumPy Random Distributions](https://numpy.org/doc/stable/reference/random/generator.html#distributions).\n",
    "\n",
    "We'll see this in action with the normal (Gaussian) distribution.\n",
    "\n",
    "```\n",
    "normal(...) method of numpy.random._generator.Generator instance\n",
    "    normal(loc=0.0, scale=1.0, size=None)\n",
    "    \n",
    "    Draw random samples from a normal (Gaussian) distribution.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    loc : float or array_like of floats\n",
    "        Mean (\"centre\") of the distribution.\n",
    "    scale : float or array_like of floats\n",
    "        Standard deviation (spread or \"width\") of the distribution. Must be\n",
    "        non-negative.\n",
    "    size : int or tuple of ints, optional\n",
    "        Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
    "        ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
    "        a single value is returned if ``loc`` and ``scale`` are both scalars.\n",
    "        Otherwise, ``np.broadcast(loc, scale).size`` samples are drawn.\n",
    "...\n",
    "```\n",
    "\n",
    "In the docstring for `rng.normal`, we can see it asks for a `loc` (mean) and `scale` (standard deviation) of the Gaussian distribution to randomly draw from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random number setup\n",
    "draw_mean_std = (10, 0.2)  # (mean, stdev)\n",
    "ndraws = 10\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "draws = rng.normal(*draw_mean_std, ndraws)\n",
    "\n",
    "print(draws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to above, we can see that after many draws, our histogram begins to look like a typical Gaussian \"bell curve\" centered at the mean with standard deviation spread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random number setup\n",
    "draw_mean_std = (10, 0.2)\n",
    "ndraws = 1000000  # <- try changing the number of draws\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "draws = rng.normal(*draw_mean_std, ndraws)\n",
    "\n",
    "# plotting \n",
    "f = plt.figure(facecolor='white', figsize=(4, 3), dpi=150)\n",
    "ax = f.subplots(1, 1)\n",
    "\n",
    "n, edges, _ = ax.hist(draws, histtype='step', range=(9, 11), bins=100)\n",
    "set_plot_axis_label(ax, 'Value', 'Count')\n",
    "\n",
    "# ax.ticklabel_format(style='sci', axis='y', scilimits=(0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo -- Uncertainty (error) Propagation\n",
    "\n",
    "Recall last week we had a simple measurement with some error associated with it.\n",
    "\n",
    "What happens when we cannot measure a quantity and its error directly but still want to estimate the errors on it?\n",
    "\n",
    "This is a job for **error propagation**!\n",
    "\n",
    "### Error propagation (analytical)\n",
    "\n",
    "If you only feed your measurement data through simple functions, we can \"propagate\" that error with the following error propagation equations:\n",
    "\n",
    "![Uncertainty Propagation](http://science.clemson.edu/physics/labs/tutorials/errorp/eptable.gif)\n",
    "\n",
    "(from Clemson University)\n",
    "\n",
    "This is the \"analytical\" way to propagate errors since we have well defined functions and can plug values in to compute the final errors.\n",
    "\n",
    "For example, say we had a study where we measured a participant's height ($H_{\\rm height}$) and then the length of their hair ($H_{\\rm hair}$). We want to find what their \"total height ($H_{\\rm total}$)\" is if they were to pull their hair straight up. \n",
    "\n",
    "$H_{\\rm total} = H_{\\rm height} + H_{\\rm hair}$\n",
    "\n",
    "You might imagine that a single measurement will sometimes give biases values, so multiple measurements of both parameters ($H_{\\rm height}$, $H_{\\rm hair}$) are the way to go. The more measurements you get from both parameters the closer the mean value will be to the true value and the smaller the uncertainty (the standard deviation, std) will be. \n",
    "\n",
    "Now, suppose you done 10 measurements for both $H_{\\rm height}$ and $H_{\\rm hair}$. As good scientists, we want an accurate way to estimate the error of the $H_{\\rm total}$. One way to do it will be just add up those 10 sets of $H_{\\rm height}$ and $H_{\\rm hair}$ values to get 10 $H_{\\rm total}$, and take a the std. The other way will be using the first formula above in the table with the means and stds of $H_{\\rm height}$ and $H_{\\rm hair}$:\n",
    "\n",
    "$$\\sigma_{H_{\\rm total}} = \\sqrt{\\sigma_{H_{\\rm height}}^2 + \\sigma_{H_{\\rm hair}}^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measurements\n",
    "heights      = np.array([1.93, 1.82, 2.08, 2.01, 1.46, 1.34, 1.75, 2.2 , 1.95])\n",
    "hair_lengths = np.array([0.01, 0.56, 0.23, 0.27, 0.21, 0.1 , 0.04, 0.06, 0.15])\n",
    "\n",
    "# Fist moethod:\n",
    "htotal = heights + hair_lengths\n",
    "\n",
    "htotal_avg = np.mean(htotal)\n",
    "htotal_std = np.std(htotal)\n",
    "\n",
    "print(f\"This person's total height using method 1 is {htotal_avg:1.2f} +/- {htotal_std:1.3f} m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second method:\n",
    "\n",
    "heights_avg = np.mean(heights)\n",
    "hair_lengths_avg = np.mean(hair_lengths)\n",
    "\n",
    "heights_std = np.std(heights)\n",
    "hair_lengths_std = np.std(hair_lengths)\n",
    "\n",
    "print(f\"The H_height = {heights_avg:1.2f} +/- {heights_std:1.3f} m\")\n",
    "print(f\"The H_hair = {hair_lengths_avg:1.2f} +/- {hair_lengths_std:1.3f} m\")\n",
    "\n",
    "htotal_avg = heights_avg + hair_lengths_avg\n",
    "htotal_std = np.sqrt(heights_std**2 + hair_lengths_std**2)\n",
    "\n",
    "print(f\"This person's total height using method 2 is {htotal_avg:1.2f} +/- {htotal_std:1.3f} m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay we got to report errors like good scientists! But we said this section was about randomness... \n",
    "\n",
    "Say now you only know the mean and std of $H_{\\rm height}$ and $H_{\\rm hair}$, is it still possible to get the uncertainty of $H_{\\rm total}$ using the first method?? Want to avoid the fancy error propagation formulas... Here is when the MC error propagation come it!\n",
    "\n",
    "The idea here is that as long as our errors are normal (Gaussian), we can randomly draw $H_{\\rm height}$ and $H_{\\rm hair}$ values from a Gaussian distribution based on the mean and std of $H_{\\rm height}$ and $H_{\\rm hair}$. With these values, we can calculate the $\\sigma_{H_{\\rm total}}$ using the first method.\n",
    "\n",
    "We already know how to draw values from a Gaussian using our RNG so let's try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with the same data and add it, compute the mean as usual\n",
    "heights = np.array([1.93, 1.82, 2.08, 2.01, 1.46, 1.34, 1.75, 2.2 , 1.95])\n",
    "hair_lengths = np.array([0.01, 0.56, 0.23, 0.27, 0.21, 0.1 , 0.04, 0.06, 0.15])\n",
    "\n",
    "h_totals = heights + hair_lengths\n",
    "\n",
    "ndraws = 1000000\n",
    "rng = np.random.default_rng(seed=100)  # <- remove seed to see other random results\n",
    "\n",
    "# Make our random arrays using the mean, standard dev of our measurements\n",
    "g_height = rng.normal(np.mean(heights), np.std(heights), ndraws)\n",
    "g_hair   = rng.normal(np.mean(hair_lengths), np.std(hair_lengths), ndraws)\n",
    "\n",
    "# Feed the gaussian samples through the sum\n",
    "g_total_arr = g_height + g_hair\n",
    "h_mean = np.mean(g_total_arr)\n",
    "\n",
    "# Because the error propagation formula for mean is just a standard deviation\n",
    "# we can estimate the error of the mean with the stdev of our total array\n",
    "g_mean_err = np.std(g_total_arr)\n",
    "\n",
    "# Now we report the same meanbut can use the gaussian standard dev as the err\n",
    "print(f\"Mean total height (N={ndraws}): {h_mean:.2f} +/- {g_mean_err:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The larger the ndraws you use, the more stable the g_mean_err will be.\n",
    "\n",
    "We can try increasing the number of draws by hand to see when it levels out, but we have the power of code!\n",
    "\n",
    "Let's write up some code to see how many draws we need to get a stable g_mean_err.\n",
    "\n",
    "We can define stable as *changes by less than* $10^{-4}$ for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using for loop\n",
    "rng = np.random.default_rng(seed=100)\n",
    "g_mean_err_old = np.inf  # Pick large value to start us off\n",
    "\n",
    "for ndraws in np.logspace(1, 7, 10):\n",
    "    ndraws = int(ndraws)\n",
    "    g_height = rng.normal(np.mean(heights), np.std(heights), ndraws)\n",
    "    g_hair = rng.normal(np.mean(hair_lengths), np.std(hair_lengths), ndraws)\n",
    "    g_total_arr = g_height + g_hair\n",
    "    g_mean_err = np.std(g_total_arr)\n",
    "    \n",
    "    delta_err = np.abs(g_mean_err_old - g_mean_err)\n",
    "    print(f'N={ndraws:.1e}: err={g_mean_err:.3f} (changed by {delta_err:.1e})')\n",
    "    if delta_err < 1e-4: \n",
    "        print('Changed by < 1e-4! Exiting loop...')\n",
    "        break\n",
    "    g_mean_err_old = g_mean_err\n",
    "\n",
    "print(f'\\n The uncertainty of the total height is about: {g_mean_err:1.3f} N={ndraws}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using while loop\n",
    "g_mean_err_old = np.inf  # <- something big to start us off\n",
    "delta_err = np.inf\n",
    "ndraws_arr = np.logspace(1, 7, 10)\n",
    "rng = np.random.default_rng(seed=100)\n",
    "\n",
    "# Stop loop when the difference drops below 1e-4\n",
    "i = 0\n",
    "while delta_err >= 1e-4:\n",
    "    ndraws = int(ndraws_arr[i])\n",
    "    g_height = rng.normal(np.mean(heights), np.std(heights), ndraws)\n",
    "    g_hair   = rng.normal(np.mean(hair_lengths), np.std(hair_lengths), ndraws)\n",
    "    g_total_arr = g_height + g_hair\n",
    "    g_mean_err = np.std(g_total_arr)\n",
    "\n",
    "    delta_err = np.abs(g_mean_err - g_mean_err_old)\n",
    "    print(f'N={ndraws:.1e}: err={g_mean_err:.3f} (changed by {delta_err:.1e})')\n",
    "    \n",
    "    g_mean_err_old = g_mean_err\n",
    "    i += 1\n",
    "    \n",
    "# Now we can report our mean with confidence in our error precision \n",
    "print(f'\\n The uncertainty of the total height is about: {g_mean_err:1.3f} with N={ndraws}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have an \"empirical\" estimate of our final error which didn't need error propagation formulas! \n",
    "\n",
    "Monte Carlo error propagation is particularly useful when you need to do a lot of manipulations to your data and don't want to write out all the propagation formulas by hand. It is also useful when your analysis involves more complicated functions than just addition, subtraction, multiplication, division (e.g., exponentials, logarithms, other non-linear functions, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Assignment 1] \n",
    "\n",
    "If you have something like\n",
    "$$\n",
    "\\rho = \\frac{m}{V} = \\frac{m}{\\pi r^2 (h/3)} = \\frac{3m}{\\pi r^2 h}\n",
    "$$\n",
    "How fast can you get the error of the density ($\\rho$) propagated from errors of $m$, $r$, and $h$?\n",
    "\n",
    "|                 | units | values | uncertainty ($\\sigma$) |\n",
    "|-----------------|:-----:|:------:|:----------------------:|\n",
    "| Mass (m)        |   g   |  55.5  |          4.52          |\n",
    "| Cone radius (r) |   cm  |  14.2  |          1.11          |\n",
    "| Cone height (h) |   cm  |   9.9  |          0.59          |\n",
    "\n",
    "modified from [Steve Spicklemire's youtube video](https://www.youtube.com/watch?v=V4U6RFI6HW8&t=298s)\n",
    "\n",
    "1. Estimate the error of the density ($\\rho$)\n",
    "2. How many draws (`ndwars`) do we need to get a stable $\\rho$ value? (follow the steps in the previous code cell)\n",
    "\n",
    "## [Challenge!]\n",
    "\n",
    "1. Use a more strict stable condition: `differ < 1e-6` must meet for 10 consecutive `ndraws`\n",
    "2. Find a better/faster way to reach that stable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [your code here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo -- Bootstrapping\n",
    "\n",
    "We can also use Monte Carlo methods to \"bootstrap\" confidence intervals on our measured quantities. This is often useful when we have a small sample of measurements and don't know the errors involved. Using the scatter inherent in our data and our handy random number generator, we can still get a statistical measure of errors as confidence intervals, pulling the data up by its bootstraps.\n",
    "\n",
    "**Note:** The main assumption with bootstrapping is that all measurements are *iid normal*, meaning each observation was collected independently of other measurements and is expected to have normal (Gaussian) errors.\n",
    "\n",
    "Modified from [Introduction to Statistical Methodology, Second Edition Chaper 3](https://bookdown.org/dereksonderegger/570/3-confidence-intervals-via-bootstrapping.html)\n",
    "\n",
    "Let's read in an array of data that measures the mercury levels of several lakes in Florida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll do a deep dive on pandas soon! for now we're just using it to get data\n",
    "import pandas as pd\n",
    "df = pd.read_csv('https://www.lock5stat.com/datasets3e/FloridaLakes.csv')\n",
    "avg_mercury = df['AvgMercury'].to_numpy()\n",
    "print('N measurements:', len(avg_mercury))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a histogram to see what we're looking at!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram \n",
    "fig, ax = plt.subplots(facecolor='white', figsize=(4,3), dpi=150)\n",
    "set_plot_axis_label(ax, 'Avg mercury', 'Count')\n",
    "ax.set_title('Mercury level in Florida Lakes', size='medium', fontname='Helvetica')\n",
    "ax.hist(avg_mercury, histtype='step', range=(0, np.max(avg_mercury)), bins=10,\n",
    "        color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm this histogram doesn't look very Gaussian... it seems a little skewed (not symmetrical). \n",
    "\n",
    "When we have a skewed distribution, the mean of the value is not always the best measure of the center of the values. Also, what would the standard deviation be? So far we've only seen symmetrical scatter in our data...\n",
    "\n",
    "We can still calculate them but they may not represent the data as nicely as the examples we've seen so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Mean mercury in Florida lakes is {np.mean(avg_mercury):1.2f}, +/- {np.std(avg_mercury):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have small numbers of observations that are skewed, we can't always be confident that the mean and standard deviation are good measures of the underlying distribution in our data. This is where **bootstrapping** becomes very useful!\n",
    "\n",
    "This time we will use `rng.choice()`.\n",
    "\n",
    "```\n",
    "choice(a, size=None, replace=True, p=None, axis=0, shuffle=True)\n",
    "\n",
    "Generates a random sample from a given array\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "a : {array_like, int}\n",
    "    If an ndarray, a random sample is generated from its elements.\n",
    "    If an int, the random sample is generated from np.arange(a).\n",
    "size : {int, tuple[int]}, optional\n",
    "    Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
    "    ``m * n * k`` samples are drawn from the 1-d `a`. If `a` has more\n",
    "    than one dimension, the `size` shape will be inserted into the\n",
    "    `axis` dimension, so the output ``ndim`` will be ``a.ndim - 1 +\n",
    "    len(size)``. Default is None, in which case a single value is\n",
    "    returned.\n",
    "replace : bool, optional\n",
    "    Whether the sample is with or without replacement. Default is True,\n",
    "    meaning that a value of ``a`` can be selected multiple times.\n",
    "p : 1-D array_like, optional\n",
    "    The probabilities associated with each entry in a.\n",
    "    If not given, the sample assumes a uniform distribution over all\n",
    "    entries in ``a``.\n",
    "...\n",
    "```\n",
    "\n",
    "In **bootstrapping** we want to resample the same number of data points **with replacement**, meaning the same values can be drawn multiple times. This also means we need to set `replace=True` in our `choice()` method (but since this is the default we're ok not specifying it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "ndraws = len(avg_mercury)  # Take same number of draws as in the measurement\n",
    "avg_mercury_resamp = rng.choice(avg_mercury, ndraws)  # replace=True by default\n",
    "print(avg_mercury_resamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we'll plot the original mean as a vertical black line and the mean of the resampled array as a vertical red line using `ax.axvline()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up plot \n",
    "fig, ax = plt.subplots(facecolor='white', figsize=(4,3), dpi=150 )\n",
    "set_plot_axis_label(ax, 'Avg mercury', 'Count')\n",
    "ax.set_title('Mercury level in Florida Lakes', size='medium', fontname='Helvetica')\n",
    "\n",
    "# Plot original and mean\n",
    "ax.hist(avg_mercury, histtype='step', range=(0, np.max(avg_mercury)), bins=10, \n",
    "        color='black')\n",
    "ax.axvline(np.mean(avg_mercury), lw=1, color='black', ls='--')\n",
    "\n",
    "# Plot resampled histogram and mean\n",
    "avg_mercury_resamp = rng.choice(avg_mercury, len(avg_mercury))\n",
    "ax.hist(avg_mercury_resamp, histtype='step', range=(0, np.max(avg_mercury)), bins=10,\n",
    "        color='tab:red')\n",
    "ax.axvline(np.mean(avg_mercury_resamp), lw=1, color='tab:red', ls='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be surprising that the mean has changed! All we did was resample from the original data and take the mean. If we do this many time, we'll get a distribution of means which we can think of as a set of possible outcomes if we had taken the measurements again and again.\n",
    "\n",
    "Because we are reusing the same measurements to resample, this won't make our mean any more accurate (because we have no new data to go off of).\n",
    "\n",
    "What this *does* do is show us how much our mean would vary if we repeated our experiment many times with the same number of observations and similar scatter in the data... It's a new way to **bootstrap** uncertainty when we didn't have any info about the error arrays to do error propagation!\n",
    "\n",
    "Below, let's rum our resampling a bunch of times and see what values we get for the mean..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting \n",
    "fig, ax = plt.subplots(facecolor='white', figsize=(4,3), dpi=150)\n",
    "set_plot_axis_label(ax, 'Avg mercury', 'Count')\n",
    "ax.set_title('Mercury level in Florida Lakes', size='medium', fontname='Helvetica')\n",
    "\n",
    "ax.axvline(np.mean(avg_mercury), lw=1, color='black', ls='--')\n",
    "\n",
    "# random draw result\n",
    "sample_times = 100000\n",
    "\n",
    "mean_collection = []\n",
    "for _ in range(sample_times): \n",
    "        avg_mercury_resamp = rng.choice(avg_mercury, len(avg_mercury))\n",
    "        mean_collection.append(np.mean(avg_mercury_resamp))\n",
    "\n",
    "ax.hist(mean_collection, histtype='step', color='tab:red', bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a normal (Gaussian) distribution, so we can talk about the dispersion of the mean in terms of the standard deviation! \n",
    "\n",
    "Now we can report the uncertainty of the mean on our original plot in a more satisfying way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up plot \n",
    "fig, ax = plt.subplots(facecolor='white', figsize=(4,3), dpi=150 )\n",
    "set_plot_axis_label(ax, 'Avg mercury', 'Count')\n",
    "ax.set_title('Mercury level in Florida Lakes', size='medium', fontname='Helvetica')\n",
    "\n",
    "# Plot original and mean\n",
    "ax.hist(avg_mercury, histtype='step', range=(0, np.max(avg_mercury)), bins=10, \n",
    "        color='black')\n",
    "ax.axvline(np.mean(avg_mercury), lw=1, color='black', ls='--')\n",
    "\n",
    "# Calculate the 95% confidence interval [2.5%, 97.5%]\n",
    "pct95_low = np.percentile(mean_collection, 2.5)\n",
    "pct95_upp = np.percentile(mean_collection, 97.5)\n",
    "ax.axvline(pct95_low, lw=1, color='tab:blue', ls='--', label='95th pct')\n",
    "ax.axvline(pct95_upp, lw=1, color='tab:blue', ls='--')\n",
    "ax.legend()\n",
    "\n",
    "print(f'Mean mercury in Florida lakes is {np.mean(avg_mercury):1.2f}', end='')\n",
    "print(f' with a 95% confidence interval of [{pct95_low:.2f}, {pct95_upp:.2f}]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using the distribution of the bootstrapped means, we can capture the scatter in our data with N=59 observations if we were to repeat the trial many times. \n",
    "\n",
    "Now we can say we are 95% confident that the true mean mercury in Florida lakes is within our 95% confidence interval, given the measurements we made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Assignment 2] What's the value for $\\pi$?\n",
    "\n",
    "In this assignment, you will need to use the MC method to estimate the values of $\\pi$.\n",
    "\n",
    "Assuming you have a quarter circle with the radius of 1 and a square that share it's edge with the quarter circle's \n",
    "radius (see the plot below). \n",
    "\n",
    "![Monte-Carlo pi](https://helloacm.com/wp-content/uploads/2015/11/Monte-Carlo01.jpg)\n",
    "\n",
    "Therefore, we know:\n",
    "$$\n",
    "Area_{\\rm quarter\\ circle} = \\pi r^2/4 \\\\\n",
    "Area_{\\rm square} = r^2\n",
    "$$\n",
    "The ratio of the two will be\n",
    "$$\n",
    "\\frac{Area_{\\rm quarter\\ circle}}{Area_{\\rm square}} = \\frac{\\pi r^2/4}{r^2} = \\frac{\\pi}{4}\n",
    "$$\n",
    "Rearange the equation and changes the area with the number of points we have:\n",
    "$$\n",
    "\\pi = 4 \\frac{Area_{\\rm quarter\\ circle}}{Area_{\\rm square}} = 4 \\frac{N_{\\rm quarter\\ circle}}{N_{\\rm square}}\n",
    "$$\n",
    "where $N_{\\rm quarter\\ circle}$ is the number of points within the quarter circle and $N_{\\rm square}$ is the number of points\n",
    "within the square.\n",
    "\n",
    "Tips:\n",
    "1. You will need to generate two arrays with the random generator as the x and y axis of each points.\n",
    "2. Calculate the number of points within the quarter circle and within the square\n",
    "3. You get $\\pi$ by dividing the two numbers and times 4\n",
    "\n",
    "**Show that your $\\pi$ has $< 1e-15$ difference from `np.pi`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [your code here]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f80b920db57ddf6729f1c3d73eef5d58e783dc11850fd4dafb78bae7877f3ad"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('spirl': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
